{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow.\n",
    "\n",
    "Let's get our vectorDB from before.\n",
    "\n",
    "# VECTOR STORE RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../.env')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lark\n",
      "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Downloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m748.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lark\n",
      "Successfully installed lark-1.1.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "persist_directory = '../docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Diversity: Maximum marginal relevance\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    "\n",
    "Maximum marginal relevance strives to achieve both relevance to the query and diversity among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Email\\t(AIOU\\temployees\\tonly)\\nFAQ's\\t\\nFinancial\\tSupport\\tScheme\\t\\nICMAP\\tStudy\\tMaterial\\t\\nJamia\\tNama\\t\\nJobs\\t\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Email\\t(AIOU\\temployees\\tonly)\\nFAQ's\\t\\nFinancial\\tSupport\\tScheme\\t\\nICMAP\\tStudy\\tMaterial\\t\\nJamia\\tNama\\t\\nJobs\\t\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in results with MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 18, updating n_results = 18\n"
     ]
    }
   ],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Email\\t(AIOU\\temployees\\tonly)\\nFAQ's\\t\\nFinancial\\tSupport\\tScheme\\t\\nICMAP\\tStudy\\tMaterial\\t\\nJamia\\tNama\\t\\nJobs\\t\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'university\\tof\\tAsia\\tin\\tdistance\\teducation,\\twhich\\tprimarily\\tfocuses\\ton\\tthe\\teducational\\tneeds\\tof\\tmasses'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Specificity: working with metadata\n",
    "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on metadata.\n",
    "\n",
    "metadata provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = vectordb.similarity_search(\n",
    "#     question,\n",
    "#     k=3,\n",
    "#     filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in docs:\n",
    "#     print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Specificity: working with metadata using self-query retriever\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use SelfQueryRetriever, which uses an LLM to extract:\n",
    "\n",
    "The query string to use for vector search\n",
    "A metadata filter to pass in as well\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The default model for OpenAI (\"from langchain.llms import OpenAI\") is text-davinci-003. Due to the deprication of OpenAI's model text-davinci-003 on 4 January 2024, you'll be using OpenAI's recommended replacement model gpt-3.5-turbo-instruct instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will receive a warning about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored.\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional tricks: compression\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Financial\tSupport\tScheme\t\n",
      "Workshop\tSchedule\t\n",
      "Financial\tSupport\tScheme\t\n",
      "Workshop\tSchedule\t\n",
      "Whats\tHappening\tNews\t&\tEvents\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Financial\tSupport\tScheme\t\n",
      "Workshop\tSchedule\t\n",
      "Financial\tSupport\tScheme\t\n",
      "Workshop\tSchedule\t\n",
      "Whats\tHappening\tNews\t&\tEvents\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Allama\tIqbal\tOpen\tUniversity,\tthe\tlargest\tuniversity\tof\tAsia\tin\tdistance\teducation,\twhich\n",
      "primarily\tfocuses\ton\tthe\teducational\tneeds\tof\tmasses\tby\tproviding\tquality\teducation\tat\ttheir\tdoorsteps\tall\tover\tthe\tcountry\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Allama\tIqbal\tOpen\tUniversity,\tthe\tlargest\tuniversity\tof\tAsia\tin\tdistance\teducation,\twhich\n",
      "primarily\tfocuses\ton\tthe\teducational\tneeds\tof\tmasses\tby\tproviding\tquality\teducation\tat\ttheir\tdoorsteps\tall\tover\tthe\tcountry\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 18, updating n_results = 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Financial\tSupport\tScheme\t\n",
      "Workshop\tSchedule\t\n",
      "Financial\tSupport\tScheme\t\n",
      "Workshop\tSchedule\t\n",
      "Whats\tHappening\tNews\t&\tEvents\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other types of retrieval\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents.\n",
    "\n",
    "The LangChain retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"../docs/pdf/data.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/harry/anaconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m688.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m536.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harry/anaconda3/envs/llm/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/harry/anaconda3/envs/llm/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Email\\t(AIOU\\temployees\\tonly)\\nFAQ's\\t\\nFinancial\\tSupport\\tScheme\\t\\nICMAP\\tStudy\\tMaterial\\t\\nJamia\\tNama\\t\\nJobs\\t\\nMIT\\tOpen\\tCourseware\\t\\nNews\\t&\\tViews\\t\\nOAS\\t(For\\nProgram\\tCoordinators)\\t\\nOverseas\\t\\nPakistan\\tCitizen's\\tPortal\\t\\nPakistan\\tInfographic\\t\\nQuality\\tEnhancement\\t\\nRTI\\t(Right\\tTo\\tInformation)\\nRegional\\tCampuses\\t\\nSwift\\tCenter\\t\\nTender\\tNotices\\t\\nHome\\t\\nApply\\tOnline\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\t\\nApply\\tOnline\\t\\nAdmission\\t(OAS)\\t\\nEnrollment\\n(CMS)\\t\\nAaghi\\t(LMS)\\t\\nAcademic\\tCalender\\t\\nResults\\t\\nBooks\\t\\nWhat\\twe\\tdo?\\tStudent\\tServices\\t\\nDate\\tSheet\\t\\nBook\\tTracking\\t\\nDownloads\\nAssignments\\t\\nFinancial\\tSupport\\tScheme\\t\\nWorkshop\\tSchedule\\t\\nDate\\tSheet\\t\\nfas\\tfa-calendar-alt\\t\\nRead\\tmore\\t\\nBook\\tTracking\\t\\nfas\\tfa-\\nwarehouse\\t\\nRead\\tmore\\t\\nDownloads\\t\\nfas\\tfa-download\\t\\nRead\\tmore\\t\\nAssignments\\t\\nfas\\tfa-book\\tRead\\tmore\\t\\nFinancial\\tSupport\\tScheme\\t\\nfas\\nfa-hand-holding-usd\\tRead\\tmore\\t\\nWorkshop\\tSchedule\\t\\nfas\\tfa-calendar-check\\tRead\\tmore\\t\\nWhats\\tHappening\\tNews\\t&\\tEvents\\t\\nLast\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Email\\t(AIOU\\temployees\\tonly)\\nFAQ's\\t\\nFinancial\\tSupport\\tScheme\\t\\nICMAP\\tStudy\\tMaterial\\t\\nJamia\\tNama\\t\\nJobs\\t\\nMIT\\tOpen\\tCourseware\\t\\nNews\\t&\\tViews\\t\\nOAS\\t(For\\nProgram\\tCoordinators)\\t\\nOverseas\\t\\nPakistan\\tCitizen's\\tPortal\\t\\nPakistan\\tInfographic\\t\\nQuality\\tEnhancement\\t\\nRTI\\t(Right\\tTo\\tInformation)\\nRegional\\tCampuses\\t\\nSwift\\tCenter\\t\\nTender\\tNotices\\t\\nHome\\t\\nApply\\tOnline\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\t\\nApply\\tOnline\\t\\nAdmission\\t(OAS)\\t\\nEnrollment\\n(CMS)\\t\\nAaghi\\t(LMS)\\t\\nAcademic\\tCalender\\t\\nResults\\t\\nBooks\\t\\nWhat\\twe\\tdo?\\tStudent\\tServices\\t\\nDate\\tSheet\\t\\nBook\\tTracking\\t\\nDownloads\\nAssignments\\t\\nFinancial\\tSupport\\tScheme\\t\\nWorkshop\\tSchedule\\t\\nDate\\tSheet\\t\\nfas\\tfa-calendar-alt\\t\\nRead\\tmore\\t\\nBook\\tTracking\\t\\nfas\\tfa-\\nwarehouse\\t\\nRead\\tmore\\t\\nDownloads\\t\\nfas\\tfa-download\\t\\nRead\\tmore\\t\\nAssignments\\t\\nfas\\tfa-book\\tRead\\tmore\\t\\nFinancial\\tSupport\\tScheme\\t\\nfas\\nfa-hand-holding-usd\\tRead\\tmore\\t\\nWorkshop\\tSchedule\\t\\nfas\\tfa-calendar-check\\tRead\\tmore\\t\\nWhats\\tHappening\\tNews\\t&\\tEvents\\t\\nLast\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
