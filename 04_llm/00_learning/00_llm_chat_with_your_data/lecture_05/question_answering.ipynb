{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Recall the overall workflow for retrieval augmented generation (RAG):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed `Document Loading` and `Splitting` as well as `Storage` and `Retrieval`.\n",
    "\n",
    "Let's load our vectorDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was added to assign the openai LLM version filmed until it is deprecated, currently in Sept 2023. LLM responses can often vary, but the responses may be significantly different when using a different model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = '../docs/chroma'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harry/anaconda3/envs/llm/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have enough information to determine the specific class or course you are referring to. If you can provide more context or details about the class, I may be able to assist you in identifying the major topics covered in that course.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know, thanks for asking!\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Email\\t(AIOU\\temployees\\tonly)\\nFAQ's\\t\\nFinancial\\tSupport\\tScheme\\t\\nICMAP\\tStudy\\tMaterial\\t\\nJamia\\tNama\\t\\nJobs\\t\\nMIT\\tOpen\\tCourseware\\t\\nNews\\t&\\tViews\\t\\nOAS\\t(For\\nProgram\\tCoordinators)\\t\\nOverseas\\t\\nPakistan\\tCitizen's\\tPortal\\t\\nPakistan\\tInfographic\\t\\nQuality\\tEnhancement\\t\\nRTI\\t(Right\\tTo\\tInformation)\\nRegional\\tCampuses\\t\\nSwift\\tCenter\\t\\nTender\\tNotices\\t\\nHome\\t\\nApply\\tOnline\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\nÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\tÂ\\t\\t\\nApply\\tOnline\\t\\nAdmission\\t(OAS)\\t\\nEnrollment\\n(CMS)\\t\\nAaghi\\t(LMS)\\t\\nAcademic\\tCalender\\t\\nResults\\t\\nBooks\\t\\nWhat\\twe\\tdo?\\tStudent\\tServices\\t\\nDate\\tSheet\\t\\nBook\\tTracking\\t\\nDownloads\\nAssignments\\t\\nFinancial\\tSupport\\tScheme\\t\\nWorkshop\\tSchedule\\t\\nDate\\tSheet\\t\\nfas\\tfa-calendar-alt\\t\\nRead\\tmore\\t\\nBook\\tTracking\\t\\nfas\\tfa-\\nwarehouse\\t\\nRead\\tmore\\t\\nDownloads\\t\\nfas\\tfa-download\\t\\nRead\\tmore\\t\\nAssignments\\t\\nfas\\tfa-book\\tRead\\tmore\\t\\nFinancial\\tSupport\\tScheme\\t\\nfas\\nfa-hand-holding-usd\\tRead\\tmore\\t\\nWorkshop\\tSchedule\\t\\nfas\\tfa-calendar-check\\tRead\\tmore\\t\\nWhats\\tHappening\\tNews\\t&\\tEvents\\t\\nLast\", metadata={'page': 0, 'source': '../docs/pdf/data.pdf'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA chain types\n",
    "QA fails to preserve conversational history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RetrievalQA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qa_chain \u001b[38;5;241m=\u001b[39m \u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m      2\u001b[0m     llm,\n\u001b[1;32m      3\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mvectordb\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RetrievalQA' is not defined"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, there is no specific mention of probability as a class topic at AIOU (Allama Iqbal Open University). Therefore, I don't have information to confirm if probability is a class topic at AIOU.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have enough information to answer your question about why prerequisites are needed.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
